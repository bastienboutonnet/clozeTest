{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close Probability Analysis Log\n",
    "## Parse Qualtrics Output\n",
    "\n",
    "#### Step 1: Import libraries, load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df=pd.read_csv('rawDat.csv',skiprows=[1,])\n",
    "df=df.rename(columns={df.columns[0]:'subj_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Step 2: Split lists\n",
    "Assuming you have an embeded data variable created by your Qualtrics survey, here `listNb` you can sort your different participants into blocks. This will extract each participant as a row, and since the columns of the other block will be empty you will want to drop those columns so as not to have empty/useless data.\n",
    "\n",
    "You then store it in a dictionary `dic` which you will increment for each list.\n",
    "\n",
    "Because pandas doesn't like to have column labels with the same name, and rightly so, it will add `.X` where `X` is a number to each duplicate column. This is going to be a problem later on when you're trying to match the column index with the sentence/row index from your *loop and merge key*.\n",
    "We therefore incorporate a step where `re.sub()` will delete a specified pattern (regular expression) consisting of everything after and including the `.`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic={}\n",
    "for curList in xrange(1,5):\n",
    "    dic[curList]=df.loc[df['listNb']==curList].dropna(1,how='all')\n",
    "    cols=list(dic[curList].columns.values) #store columns in a list\n",
    "    new_cols=[re.sub('\\..*$', \"\", elem) for elem in cols] #make the resub go through each element of the list and do its thing\n",
    "    dic[curList].columns=new_cols #replace columns back in df.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Step 3: Perform Parsing\n",
    "Here the steps are written in a function that melts and retrieves the information that we care about.\n",
    "This function is then applied in the next code cell to the different dataframes in the dictionary for each list and appends the lists back together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def melt_df_feed_info_from_loop_merge(df):\n",
    "    \n",
    "    #MELT | Transpose df into long format\n",
    "    col_names=pd.Series(df.columns)\n",
    "    valid_cols_mask=col_names.str.contains(colsToPull,regex=True)\n",
    "    valid_cols = df.columns[valid_cols_mask]\n",
    "    df=df[valid_cols]\n",
    "    df=pd.melt(df,id_vars='subj_id',var_name='qual_col',value_name=measureName)\n",
    "\n",
    "    #Extract useful information from qual_cols, and merge key info\n",
    "    qualtrics_parsed=df.qual_col.str.extract('^(?P<measure>\\w+)\\((?P<row>\\d+)\\)$')\n",
    "    qualtrics_parsed = qualtrics_parsed.convert_objects(convert_numeric=True)\n",
    "    df = pd.concat([df, qualtrics_parsed], axis = 1)\n",
    "    df = df.merge(loopmergeInfo, how='left')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colsToPull='^subj_id|Comp'\n",
    "measureName='Completion'\n",
    "\n",
    "for curList in xrange(1,5):\n",
    "    loopmergeInfo=pd.read_csv('loopmerge'+str(curList)+'.csv')\n",
    "    if len(dic[curList])>=1:\n",
    "        if curList==1:\n",
    "            reconst=melt_df_feed_info_from_loop_merge(dic[curList])\n",
    "        else:\n",
    "            reconst=reconst.append(melt_df_feed_info_from_loop_merge(dic[curList]))\n",
    "    else:\n",
    "        print('There was no data in list %d') % curList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Step 4: Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reconst.head()\n",
    "reconst.to_csv('reconstToday.csv',index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Step 4: Analyse/Visualise Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the analysis is written in R code, it basically consists of sumarising the file by sentence, completion and get a measure of popularity for each participant. These functions from the `ddply` package are likely to be operationalisable in `pandas` but I haven't worked it out yet.\n",
    "\n",
    "Follow up analysis on R (using R script). Maybe this could be analysed using Python too, but at least it works so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging DFs when several variables have been extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comp=pd.read_csv('datCompletion.csv')\n",
    "comp=comp.drop('measure',1)\n",
    "nat=pd.read_csv('datNatNess.csv')\n",
    "nat=nat.drop('measure',1)\n",
    "diff=pd.read_csv('datDiff.csv')\n",
    "diff=diff.drop('measure',1)\n",
    "RT=pd.read_csv('datRT.csv')\n",
    "RT=RT.drop('measure',1)\n",
    "comm=pd.read_csv('datAdditCom.csv')\n",
    "comm=comm.drop('measure',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compNat=pd.merge(comp,nat,on=['subj_id','sentID'],how='left')\n",
    "compNatDiff=pd.merge(compNat,diff,on=['subj_id','sentID'],how='left')\n",
    "compNatDiffRT=pd.merge(compNatDiff,RT,on=['subj_id','sentID'],how='left')\n",
    "compNatDiffRTComm=pd.merge(compNatDiffRT,comm,on=['subj_id','sentID'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compNatDiffRTComm.to_csv('allVars.csv',index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Analysis Cleanups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment Analysis\n",
    "To this file I then add a column (this was done in excel) that adds a 1 if the `additCom` column contains a comment and a 0 if it doesn't so that it can be sorted for quick review.\n",
    "\n",
    "### Typo checks\n",
    "Here's a list of steps to do:\n",
    "- split completion into determiner and word.\n",
    "- match whether answer is a word from corpus.\n",
    "- correct for typos.\n",
    "- Run actual cloze probability analyses.\n",
    "- Obtain, from a corpus, the frequencies, letter number etc. of the most popular item and come up with words from that corpus that match these frequencies. These words will then have to be used in \"silly\" filler sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj_id</th>\n",
       "      <th>Completion</th>\n",
       "      <th>sentID</th>\n",
       "      <th>NatNess</th>\n",
       "      <th>Diff</th>\n",
       "      <th>RT</th>\n",
       "      <th>hasComment?</th>\n",
       "      <th>index</th>\n",
       "      <th>AdditCom</th>\n",
       "      <th>translation</th>\n",
       "      <th>isImportant</th>\n",
       "      <th>sentenceRisk</th>\n",
       "      <th>askForCheck</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>determiner</th>\n",
       "      <th>noun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R_BKctGx9a1Hi7w4h</td>\n",
       "      <td>de thee</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de</td>\n",
       "      <td>thee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R_u2ffULg0uVmoetj</td>\n",
       "      <td>de koffie</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.748</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de</td>\n",
       "      <td>koffie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_2vf9l3GOwanVBOH</td>\n",
       "      <td>de thee</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de</td>\n",
       "      <td>thee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R_OqjAwL4brYESqul</td>\n",
       "      <td>de thee</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2.621</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de</td>\n",
       "      <td>thee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R_1LG8FwYsk4Xgq61</td>\n",
       "      <td>de koffie</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2.426</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de</td>\n",
       "      <td>koffie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             subj_id Completion  sentID  NatNess  Diff     RT  hasComment?  \\\n",
       "0  R_BKctGx9a1Hi7w4h    de thee       1        4     6  0.831            0   \n",
       "1  R_u2ffULg0uVmoetj  de koffie       1        5     5  1.748            0   \n",
       "2  R_2vf9l3GOwanVBOH    de thee       1        5     5  0.579            0   \n",
       "3  R_OqjAwL4brYESqul    de thee       1        5     6  2.621            0   \n",
       "4  R_1LG8FwYsk4Xgq61  de koffie       1        5     6  2.426            0   \n",
       "\n",
       "   index AdditCom translation  isImportant  sentenceRisk  askForCheck  \\\n",
       "0    NaN      NaN         NaN          NaN           NaN          NaN   \n",
       "1    NaN      NaN         NaN          NaN           NaN          NaN   \n",
       "2    NaN      NaN         NaN          NaN           NaN          NaN   \n",
       "3    NaN      NaN         NaN          NaN           NaN          NaN   \n",
       "4    NaN      NaN         NaN          NaN           NaN          NaN   \n",
       "\n",
       "  Unnamed: 13 determiner    noun  \n",
       "0         NaN         de    thee  \n",
       "1         NaN         de  koffie  \n",
       "2         NaN         de    thee  \n",
       "3         NaN         de    thee  \n",
       "4         NaN         de  koffie  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dat=pd.read_csv('allVarsCommentReviewed.csv') #This may change to the more \"final\" file.\n",
    "\n",
    "compSplit=dat.Completion.str.extract('^(?P<determiner>\\w+) (?P<noun>\\w+)$')\n",
    "dat=pd.concat([dat,compSplit],axis=1)\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped=dat.groupby(['sentID','Completion'])\n",
    "test=grouped['subj_id'].agg({'pop':np.size})#.reset_index()#.sort('pop')\n",
    "g=test['pop'].groupby(level=0,group_keys=False)\n",
    "res=g.apply(lambda x: x.order(ascending=False))\n",
    "res=res.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Typos and Non-Words\n",
    "#### Using Simple corpus matching\n",
    "NOTE: The SUBTLEX-NL corpus, has been edited so that it would only contain words, and spaces were removed. This is because sometimes we were getting false matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dat=pd.read_csv('testIsWordReviewed.csv') #This may change to the more \"final\" file.\n",
    "\n",
    "compSplit=dat.Completion.str.extract('^(?P<determiner>\\w+) (?P<noun>\\w+)$')\n",
    "dat=pd.concat([dat,compSplit],axis=1)\n",
    "\n",
    "corpus=pd.read_table('SUBTLEX-NL.txt')\n",
    "corpus.head()\n",
    "detCorpus=['de','het','De','Het']\n",
    "\n",
    "dat['noun']=dat.noun.fillna(-99)\n",
    "dat['isDet']=dat.determiner.isnull()\n",
    "dat['isDet']=dat.determiner.isin(detCorpus)\n",
    "dat['isWord']=dat.noun.isin(corpus.Word)\n",
    "dat.to_csv('testIsWordRevCorr.csv',index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get participants to correct typos.\n",
    "- Run actual close probability (popularity) analysis\n",
    "- Analyse further\n",
    "- Extract top value for each sentence and merge with sentence file if necessary later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Clearing aberrant answers\n",
    "- 3/11/15: done manually, by deleting non-words after typo correction\n",
    "- Create two cleaned up versions:\n",
    "    - One with no change in content destined to the fMRI design.    \n",
    "    **SUCCESS RATE**: **107** sentences that are above or equal to 70% cloze probability.\n",
    "    \n",
    "    - One with gender preseving alternate candidates (*laissez-faire* version)\n",
    "    *maybe this is not needed since it might be easier for Mareike to just generate new sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo\n",
    "### Further stimuli creation\n",
    "- Since the success rate of all sentences **107** we need at least **13** more sentences created. **>>Mareike is on it**\n",
    "    - these new sentences should be submitted to a cloze probability test.\n",
    "- We now need a bunch of filler sentences.\n",
    "\n",
    "### On current datafiles\n",
    "- The results from the cloze test needs to:\n",
    "    - be merged with the **full sentence**. **>>done**\n",
    "    - be merged with the **frequency of the best completion** from a corpus. **>>done**\n",
    "- Make sure the candidate sentences that are >70% are \"het\" or \"de\" answers. **>>done**\n",
    "- Separate determiner from noun in the completion answer so that it's easier for sorting after. **>>done**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
